<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8" />
<title>高崎商科大学 AR案内（疑似AR版）</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<style>
  html,body { height:100%; margin:0; background:#000; color:#fff; font-family:system-ui,-apple-system,Roboto,"Helvetica Neue",Arial; }
  #cameraView { position:fixed; inset:0; width:100vw; height:100vh; object-fit:cover; z-index:0; }

  #ui { position:fixed; top:8px; left:8px; z-index:10; display:flex; gap:8px; align-items:center; }
  #routeSelect { font-size:16px; padding:6px; }

  /* support area improved */
  #supportArea {
    position:fixed;
    top:8px;
    right:8px;
    width:180px;
    background:rgba(0,0,0,0.55);
    padding:10px;
    border-radius:10px;
    z-index:11;
    display:flex;
    flex-direction:column;
    gap:10px;
    align-items:center;
  }
  #supportThumb { width:160px; height:100px; object-fit:cover; border:2px solid #fff; border-radius:6px; }
  #supportText { font-size:14px; line-height:1.4; text-align:center; color:#fff; word-break:break-word; }

  #similarityBarContainer { position:fixed; top:110px; right:12px; width:160px; height:14px; background:#222; border-radius:8px; z-index:11; overflow:hidden; }
  #similarityBar { width:0%; height:100%; background:red; transition:width 220ms linear, background 120ms; }

  #arrowOverlay { position:fixed; bottom:160px; left:50%; transform:translateX(-50%); width:140px; z-index:11; display:none; }
  #textOverlay { position:fixed; bottom:36px; left:0; right:0; text-align:center; font-size:20px; text-shadow:0 0 8px #000; z-index:11; }

  /* hidden helpers */
  canvas.hidden { display:none; visibility:hidden; position:fixed; width:1px; height:1px; left:-9999px; top:-9999px; }
</style>

<!-- OpenCV.js (1回だけ) -->
<script>
  function onOpenCvReady() {
    console.log("OpenCV ready");
    window._cvReady = true;
    // initAR will be invoked in load handler below
  }
</script>
<script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>
</head>
<body>
  <video id="cameraView" autoplay playsinline muted></video>

  <div id="ui">
    <select id="routeSelect">
      <option value="route_office">正門 → 事務室</option>
      <option value="route_library">正門 → 図書館</option>
      <option value="route_cafe">正門 → カフェ</option>
      <option value="route_career">正門 → キャリアサポートセンター</option>
    </select>
  </div>

  <div id="supportArea">
    <img id="supportThumb" src="" alt="support">
    <div id="supportText">この場所に向かってください</div>
  </div>

  <div id="similarityBarContainer"><div id="similarityBar"></div></div>

  <img id="arrowOverlay" src="arrow_forward.jpg" alt="arrow">

  <div id="textOverlay">読み込み中…</div>

  <!-- hidden canvases for processing -->
  <canvas id="videoCanvas" class="hidden"></canvas>
  <canvas id="imgCanvas" class="hidden"></canvas>

<script>
/* ----------------------------
   Configuration & routes
   ---------------------------- */
const ROUTES = {
  route_office: [
    { text:"正門を出発", image:"support/gate.jpg", arrow:"arrow/go.jpg" },
    { text:"直進してください", image:"support/niwa.jpg", arrow:"arrow/tyokusinn.jpg" },
    { text:"左折してください", image:"support/1gou.jpg", arrow:"arrow/sasetu.jpg" },
    { text:"事務室前に到着", image:"support/office.jpg", arrow:"arrow/stop.jpg" }
  ],
  route_library: [
    { text:"正門を出発", image:"support/gate.jpg", arrow:"arrow/go.jpg" },
    { text:"右折してください", image:"support/niwa.jpg", arrow:"arrow/usetu.jpg" },
    { text:"直進してください", image:"support/2gou.jpg", arrow:"arrow/tyokusinn.jpg" },
    { text:"図書館前に到着", image:"support/library.jpg", arrow:"arrow/stop.jpg" }
  ],
  route_cafe: [
    { text:"正門を出発", image:"support/gate.jpg", arrow:"arrow/go.jpg" },
    { text:"直進してください", image:"support/niwa.jpg", arrow:"arrow/tyokusinn.jpg" },
    { text:"直進してください", image:"support/1gou.jpg", arrow:"arrow/tyokusinn.jpg" },
    { text:"右折してください", image:"support/3gou.jpg", arrow:"arrow/usetu.jpg" },
    { text:"カフェ前に到着", image:"support/cafe.jpg", arrow:"arrow/stop.jpg" }
  ],
  route_career: [
    { text:"正門を出発", image:"support/gate.jpg", arrow:"arrow/go.jpg" },
    { text:"直進してください", image:"support/niwa.jpg", arrow:"arrow/tyokusinn.jpg" },
    { text:"直進してください", image:"support/1gou.jpg", arrow:"arrow/tyokusinn.jpg" },
    { text:"右折してください", image:"support/3gou.jpg", arrow:"arrow/usetu.jpg" },
    { text:"左折してください", image:"support/cafe.jpg", arrow:"arrow/sasetu.jpg" },
    { text:"キャリアサポートセンター前に到着", image:"support/career.jpg", arrow:"arrow/stop.jpg" }
  ]
};

// thresholds & matching params (tweakable)
const MATCH_GOOD_DISTANCE = 60; // absolute hamming distance threshold
const MATCH_RATIO = 0.75;      // Lowe's ratio test
const SIMILARITY_AUTO_ADV = 70; // percent to auto advance

/* ----------------------------
   State
   ---------------------------- */
let currentRouteKey = document.getElementById('routeSelect').value;
let currentRoute = ROUTES[currentRouteKey];
let currentStepIndex = 0;

let supportMats = {}; // { routeKey: [Mat, ...] }
let supportLoaded = {}; // { routeKey: boolean }

let video = document.getElementById('cameraView');
let videoCanvas = document.getElementById('videoCanvas');
let imgCanvas = document.getElementById('imgCanvas');
let videoCtx = videoCanvas.getContext('2d');
let imgCtx = imgCanvas.getContext('2d');

let smoothingSimilarity = 0; // exponential smoothing
let autoAdvanceLock = false; // prevent double-advance during reset

/* ----------------------------
   Helpers
   ---------------------------- */
function setStatus(text){ document.getElementById('textOverlay').textContent = text; }
function setSupportThumb(src){ document.getElementById('supportThumb').src = src; }
function setArrow(src){ const a=document.getElementById('arrowOverlay'); a.src = src; }

/* ----------------------------
   Preload support images into cv.Mat (grayscale)
   ---------------------------- */
async function preloadAllSupportMats() {
  for(const key of Object.keys(ROUTES)) {
    supportMats[key] = [];
    supportLoaded[key] = false;
    const steps = ROUTES[key];
    for(const step of steps){
      await new Promise((resolve)=>{
        const img = new Image();
        img.crossOrigin = "anonymous";
        img.src = step.image;
        img.onload = () => {
          const W = 320, H = 240;
          imgCanvas.width = W; imgCanvas.height = H;
          imgCtx.drawImage(img,0,0,W,H);
          try{
            let mat = cv.imread(imgCanvas);
            cv.cvtColor(mat, mat, cv.COLOR_RGBA2GRAY);
            supportMats[key].push(mat);
          }catch(e){
            console.error("cv.imread support image failed:", e);
            supportMats[key].push(null);
          }
          resolve();
        };
        img.onerror = (e)=>{ console.error("support image load error", step.image, e); supportMats[key].push(null); resolve(); };
      });
    }
    supportLoaded[key] = true;
    console.log("Preloaded support mats for", key);
  }
}

/* ----------------------------
   Camera start
   ---------------------------- */
async function startCamera() {
  try{
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio:false });
    video.srcObject = stream;
    await new Promise(r => video.onloadedmetadata = r);
    const W = 640, H = Math.round(video.videoHeight * (640/video.videoWidth));
    videoCanvas.width = W; videoCanvas.height = H;
    imgCanvas.width = 320; imgCanvas.height = 240;
    return true;
  }catch(err){
    setStatus("カメラを許可してください: " + err.message);
    console.error(err);
    return false;
  }
}

/* ----------------------------
   Show current step UI
   ---------------------------- */
function showStep() {
  const step = currentRoute[currentStepIndex];
  setSupportThumb(step.image);
  setArrow(step.arrow);
  setStatus(step.text);
  // reset bar visually
  updateSimilarityBar(0);
  smoothingSimilarity = 0;
}

/* ----------------------------
   Update similarity bar (0-100) with smoothing
   ---------------------------- */
function updateSimilarityBar(rawPct){
  // exponential smoothing (alpha)
  const alpha = 0.35;
  smoothingSimilarity = smoothingSimilarity * (1 - alpha) + rawPct * alpha;
  const pct = Math.max(0, Math.min(100, smoothingSimilarity));
  const bar = document.getElementById('similarityBar');
  bar.style.width = pct + "%";
  if(pct < 30) bar.style.background = "red";
  else if(pct >= SIMILARITY_AUTO_ADV) bar.style.background = "green";
  else bar.style.background = "yellow";
  return pct;
}

/* ----------------------------
   Improved ORB similarity computation
   - uses knnMatch + Lowe's ratio + distance threshold
   - dynamic GOOD_MATCH_TARGET based on support keypoints
   ---------------------------- */
function computeSimilarityORB() {
  if(!video.videoWidth) return 0;
  if(!supportLoaded[currentRouteKey]) return 0;
  const supportMat = supportMats[currentRouteKey][currentStepIndex];
  if(!supportMat) return 0;

  // draw video frame into videoCanvas and read
  videoCtx.drawImage(video, 0, 0, videoCanvas.width, videoCanvas.height);
  let src = null;
  let gray = null;
  try {
    src = cv.imread(videoCanvas);
    gray = new cv.Mat();
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
  } catch(e){
    if(src) src.delete();
    if(gray) gray.delete();
    console.error("cv.imread video failed", e);
    return 0;
  }

  // resize to match support scale
  let frameSmall = new cv.Mat();
  cv.resize(gray, frameSmall, new cv.Size(320,240));

  // create ORB (default) - OpenCV.js may not accept parameter on all builds
  let orb;
  try { orb = new cv.ORB(); } catch(e){ orb = new cv.ORB(); }

  let kp1 = new cv.KeyPointVector();
  let kp2 = new cv.KeyPointVector();
  let des1 = new cv.Mat();
  let des2 = new cv.Mat();

  try {
    orb.detectAndCompute(frameSmall, new cv.Mat(), kp1, des1);
    orb.detectAndCompute(supportMat, new cv.Mat(), kp2, des2);
  } catch(e){
    console.error("ORB detect failed", e);
  }

  let goodMatches = 0;
  let kp2count = Math.max(1, kp2.size());

  if(!des1.empty() && !des2.empty()){
    try {
      // knn match (k=2) and ratio test
      let bf = new cv.BFMatcher(cv.NORM_HAMMING, false);
      let matches = new cv.DMatchVectorVector();
      bf.knnMatch(des1, des2, matches, 2);

      for(let i=0;i<matches.size();i++){
        let mv = matches.get(i);
        if(mv.size() < 2) { mv.delete(); continue; }
        let m = mv.get(0);
        let n = mv.get(1);
        if(m.distance < MATCH_RATIO * n.distance && m.distance <= MATCH_GOOD_DISTANCE){
          goodMatches++;
        }
        mv.delete();
      }
      matches.delete();
      bf.delete();
    } catch(e) {
      // fallback: single match counting if knnMatch not available
      try {
        let bf2 = new cv.BFMatcher(cv.NORM_HAMMING, true);
        let singleMatches = new cv.DMatchVector();
        bf2.match(des1, des2, singleMatches);
        for(let i=0;i<singleMatches.size();i++){
          if(singleMatches.get(i).distance <= MATCH_GOOD_DISTANCE) goodMatches++;
        }
        singleMatches.delete();
        bf2.delete();
      } catch(err2){
        console.error("Matcher fallback failed", err2);
      }
    }
  }

  // dynamic target based on support keypoints (12% of support kp, min 10)
  const target = Math.max(10, Math.floor(kp2count * 0.12));
  let similarity = Math.min(100, (goodMatches / target) * 100);

  // cleanup
  try{ src.delete(); }catch(e){}
  try{ gray.delete(); }catch(e){}
  try{ frameSmall.delete(); }catch(e){}
  try{ des1.delete(); des2.delete(); }catch(e){}
  try{ kp1.delete(); kp2.delete(); }catch(e){}
  try{ orb.delete(); }catch(e){}

  return similarity;
}

/* ----------------------------
   Auto-advance with visible feedback
   ---------------------------- */
function tryAutoAdvance(similarity) {
  // use smoothed percentage (updateSimilarityBar already applied smoothing)
  const pct = updateSimilarityBar(similarity);
  if(pct >= SIMILARITY_AUTO_ADV && !autoAdvanceLock){
    autoAdvanceLock = true;
    // flash green a little then advance
    const bar = document.getElementById('similarityBar');
    const prevTransition = bar.style.transition;
    bar.style.transition = "none";
    bar.style.width = "100%";
    bar.style.background = "green";
    let blink = true;
    const blinkTimer = setInterval(()=>{ bar.style.opacity = blink ? 0.25 : 1; blink = !blink; }, 180);
    setTimeout(()=>{
      clearInterval(blinkTimer);
      bar.style.opacity = 1;
      bar.style.transition = prevTransition || "width 220ms linear, background 120ms";
      // advance
      if(currentStepIndex < currentRoute.length - 1){
        currentStepIndex++;
        currentRoute = ROUTES[currentRouteKey]; // ensure current
        showStep();
      } else {
        setStatus("目的地に到着しました");
      }
      // reset and unlock after short delay
      setTimeout(()=>{ updateSimilarityBar(0); autoAdvanceLock = false; }, 300);
    }, 800);
  }
}

/* ----------------------------
   Main loop
   ---------------------------- */
function startProcessingLoop() {
  function loop(){
    if(!video.videoWidth || !supportLoaded[currentRouteKey]){ 
      requestAnimationFrame(loop); 
      return;
    }
    try{
      const sim = computeSimilarityORB();
      tryAutoAdvance(sim);
    }catch(e){
      console.error("computeSimilarityORB error", e);
    }
    requestAnimationFrame(loop);
  }
  requestAnimationFrame(loop);
}

/* ----------------------------
   initAR: waits for cv to be ready, start camera, preload images, start loop
   ---------------------------- */
async function initAR() {
  if(!window._cvReady){
    setStatus("OpenCV 初期化中…");
    const waitCV = () => new Promise(r=>{
      const check = ()=>{ if(window._cvReady) r(); else setTimeout(check,100); };
      check();
    });
    await waitCV();
  }
  setStatus("カメラ準備中…");
  const ok = await startCamera();
  if(!ok) return;

  setStatus("サポート画像読み込み中…");
  await preloadAllSupportMats();

  // init UI
  currentRouteKey = document.getElementById('routeSelect').value;
  currentRoute = ROUTES[currentRouteKey];
  currentStepIndex = 0;
  showStep();

  setStatus("準備完了：カメラをサポート画像に合わせてください");
  startProcessingLoop();
}

/* ----------------------------
   Event bindings
   ---------------------------- */
document.getElementById('routeSelect').addEventListener('change', ()=>{
  currentRouteKey = document.getElementById('routeSelect').value;
  currentRoute = ROUTES[currentRouteKey];
  currentStepIndex = 0;
  showStep();
});

/* ----------------------------
   Start
   ---------------------------- */
window.addEventListener('load', ()=>{ initAR(); });

</script>
</body>
</html>

